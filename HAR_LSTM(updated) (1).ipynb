{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.1"
    },
    "colab": {
      "name": "HAR_LSTM(updated).ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "ajSNwCWoq1Xv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Importing Libraries"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RznI6y_0q1YI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O7dePyZR00dD",
        "colab_type": "code",
        "outputId": "d6e96385-7048-42eb-ecc3-b390bf2fae0b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from zipfile import ZipFile\n",
        "file_name=\"HumanActivityRecognition.zip\"\n",
        "\n",
        "with ZipFile(file_name,'r') as zip:\n",
        "    zip.extractall()\n",
        "    print(\"Done\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vsSe7ZTGq1Yg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Activities are the class labels\n",
        "# It is a 6 class classification\n",
        "ACTIVITIES = {\n",
        "    0: 'WALKING',\n",
        "    1: 'WALKING_UPSTAIRS',\n",
        "    2: 'WALKING_DOWNSTAIRS',\n",
        "    3: 'SITTING',\n",
        "    4: 'STANDING',\n",
        "    5: 'LAYING',\n",
        "}\n",
        "\n",
        "# Utility function to print the confusion matrix\n",
        "def confusion_matrix(Y_true, Y_pred):\n",
        "    Y_true = pd.Series([ACTIVITIES[y] for y in np.argmax(Y_true, axis=1)])\n",
        "    Y_pred = pd.Series([ACTIVITIES[y] for y in np.argmax(Y_pred, axis=1)])\n",
        "\n",
        "    return pd.crosstab(Y_true, Y_pred, rownames=['True'], colnames=['Pred'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NiTXwLkYq1Yv",
        "colab_type": "text"
      },
      "source": [
        "### Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u9gjSVSbq1Yx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Data directory\n",
        "DATADIR = 'UCI_HAR_Dataset'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FdY7ZYbpq1ZM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Raw data signals\n",
        "# Signals are from Accelerometer and Gyroscope\n",
        "# The signals are in x,y,z directions\n",
        "# Sensor signals are filtered to have only body acceleration\n",
        "# excluding the acceleration due to gravity\n",
        "# Triaxial acceleration from the accelerometer is total acceleration\n",
        "SIGNALS = [\n",
        "    \"body_acc_x\",\n",
        "    \"body_acc_y\",\n",
        "    \"body_acc_z\",\n",
        "    \"body_gyro_x\",\n",
        "    \"body_gyro_y\",\n",
        "    \"body_gyro_z\",\n",
        "    \"total_acc_x\",\n",
        "    \"total_acc_y\",\n",
        "    \"total_acc_z\"\n",
        "]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5hfcXalJq1Zj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Utility function to read the data from csv file\n",
        "def _read_csv(filename):\n",
        "    return pd.read_csv(filename, delim_whitespace=True, header=None)\n",
        "\n",
        "# Utility function to load the load\n",
        "def load_signals(subset):\n",
        "    signals_data = []\n",
        "\n",
        "    for signal in SIGNALS:\n",
        "        filename = f'HAR/UCI_HAR_Dataset/{subset}/Inertial Signals/{signal}_{subset}.txt'\n",
        "        signals_data.append(\n",
        "            _read_csv(filename).to_numpy()\n",
        "        ) \n",
        "\n",
        "    # Transpose is used to change the dimensionality of the output,\n",
        "    # aggregating the signals by combination of sample/timestep.\n",
        "    # Resultant shape is (7352 train/2947 test samples, 128 timesteps, 9 signals)\n",
        "    return np.transpose(signals_data, (1, 2, 0))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6u_kCg5Hq1Z1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def load_y(subset):\n",
        "    \"\"\"\n",
        "    The objective that we are trying to predict is a integer, from 1 to 6,\n",
        "    that represents a human activity. We return a binary representation of \n",
        "    every sample objective as a 6 bits vector using One Hot Encoding\n",
        "    (https://pandas.pydata.org/pandas-docs/stable/generated/pandas.get_dummies.html)\n",
        "    \"\"\"\n",
        "    filename = f'HAR/UCI_HAR_Dataset/{subset}/y_{subset}.txt'\n",
        "    y = _read_csv(filename)[0]\n",
        "\n",
        "    return pd.get_dummies(y).to_numpy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gsa-lfG-q1aU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_data():\n",
        "    \"\"\"\n",
        "    Obtain the dataset from multiple files.\n",
        "    Returns: X_train, X_test, y_train, y_test\n",
        "    \"\"\"\n",
        "    X_train, X_test = load_signals('train'), load_signals('test')\n",
        "    y_train, y_test = load_y('train'), load_y('test')\n",
        "\n",
        "    return X_train, X_test, y_train, y_test"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eVMfpgPRq1ak",
        "colab_type": "code",
        "outputId": "491723c0-6bec-4075-b43f-10c534efe6f6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 491
        }
      },
      "source": [
        "# Importing tensorflow\n",
        "np.random.seed(42)\n",
        "import tensorflow as tf\n",
        "tf.compat.v1.set_random_seed(42)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will switch to TensorFlow 2.x on the 27th of March, 2020.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now\n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8UmJWU3OVmkO",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q9gr9x5lq1a3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Configuring a session\n",
        "session_conf = tf.compat.v1.ConfigProto(\n",
        "    intra_op_parallelism_threads=1,\n",
        "    inter_op_parallelism_threads=1\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T61piXqEq1cW",
        "colab_type": "code",
        "outputId": "ed6dc432-e548-4e67-d2b4-9c5369003c3b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Import Keras\n",
        "from keras import backend as K\n",
        "sess = tf.compat.v1.Session(graph=tf.compat.v1.get_default_graph(), config=session_conf)\n",
        "K.set_session(sess)\n",
        "#tf.compat.v1.Session()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pyc05w1Sq1cn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Importing libraries\n",
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM\n",
        "from keras.layers.core import Dense, Dropout"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rD7gsw75q1eZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Initializing parameters\n",
        "epochs = 30\n",
        "batch_size = 16\n",
        "n_hidden = 32"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ytC3GPrCq1e6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Utility function to count the number of classes\n",
        "def _count_classes(y):\n",
        "    return len(set([tuple(category) for category in y]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u8BW3z5Uq1fu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Loading the train and test data\n",
        "X_train, X_test, Y_train, Y_test = load_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hWEc84yaq1gE",
        "colab_type": "code",
        "outputId": "7483a9ad-60df-49bb-bd2d-0c5539873b41",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "timesteps = len(X_train[0])\n",
        "input_dim = len(X_train[0][0])\n",
        "n_classes = _count_classes(Y_train)\n",
        "\n",
        "print(timesteps)\n",
        "print(input_dim)\n",
        "print(len(X_train))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "128\n",
            "9\n",
            "7352\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YyiqG2MlKGk3",
        "colab_type": "code",
        "outputId": "4a0962f7-4c13-4e04-9bb1-3e3de66fe89b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 751
        }
      },
      "source": [
        "!pip install tensorflow==1.14.0"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow==1.14.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/de/f0/96fb2e0412ae9692dbf400e5b04432885f677ad6241c088ccc5fe7724d69/tensorflow-1.14.0-cp36-cp36m-manylinux1_x86_64.whl (109.2MB)\n",
            "\u001b[K     |████████████████████████████████| 109.2MB 77kB/s \n",
            "\u001b[?25hRequirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (0.8.1)\n",
            "Collecting tensorboard<1.15.0,>=1.14.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/91/2d/2ed263449a078cd9c8a9ba50ebd50123adf1f8cfbea1492f9084169b89d9/tensorboard-1.14.0-py3-none-any.whl (3.1MB)\n",
            "\u001b[K     |████████████████████████████████| 3.2MB 35.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.0.8)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.12.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.28.1)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (0.9.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.1.0)\n",
            "Requirement already satisfied: numpy<2.0,>=1.14.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.18.2)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.12.1)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (0.2.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (0.34.2)\n",
            "Collecting tensorflow-estimator<1.15.0rc0,>=1.14.0rc0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3c/d5/21860a5b11caf0678fbc8319341b0ae21a07156911132e0e71bffed0510d/tensorflow_estimator-1.14.0-py2.py3-none-any.whl (488kB)\n",
            "\u001b[K     |████████████████████████████████| 491kB 50.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (0.3.3)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (3.10.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.1.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (46.1.3)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (3.2.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow==1.14.0) (2.10.0)\n",
            "Installing collected packages: tensorboard, tensorflow-estimator, tensorflow\n",
            "  Found existing installation: tensorboard 2.2.0\n",
            "    Uninstalling tensorboard-2.2.0:\n",
            "      Successfully uninstalled tensorboard-2.2.0\n",
            "  Found existing installation: tensorflow-estimator 2.2.0rc0\n",
            "    Uninstalling tensorflow-estimator-2.2.0rc0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.2.0rc0\n",
            "  Found existing installation: tensorflow 2.2.0rc2\n",
            "    Uninstalling tensorflow-2.2.0rc2:\n",
            "      Successfully uninstalled tensorflow-2.2.0rc2\n",
            "Successfully installed tensorboard-1.14.0 tensorflow-1.14.0 tensorflow-estimator-1.14.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "tensorboard",
                  "tensorflow"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uQPp93gVq1gj",
        "colab_type": "text"
      },
      "source": [
        "- Defining the Architecture of LSTM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u9nAmBviq1gs",
        "colab_type": "code",
        "outputId": "c829a7d7-66ac-4720-9d35-0d3eadfddac8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 462
        }
      },
      "source": [
        "# Initiliazing the sequential model\n",
        "model = Sequential()\n",
        "# Configuring the parameters\n",
        "model.add(LSTM(n_hidden, input_shape=(timesteps, input_dim)))\n",
        "# Adding a dropout layer\n",
        "model.add(Dropout(0.5))\n",
        "# Adding a dense output layer with sigmoid activation\n",
        "model.add(Dense(n_classes, activation='sigmoid'))\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_1 (LSTM)                (None, 32)                5376      \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 6)                 198       \n",
            "=================================================================\n",
            "Total params: 5,574\n",
            "Trainable params: 5,574\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PjeYlrI5q1g3",
        "colab_type": "code",
        "outputId": "b5e88121-b07f-477e-c02c-472ae1816b60",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "# Compiling the model\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='rmsprop',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oUZEFwFnq1hD",
        "colab_type": "code",
        "outputId": "344b411b-6dcc-40ed-ecba-4d7d591fa903",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Training the model\n",
        "model.fit(X_train,\n",
        "          Y_train,\n",
        "          batch_size=batch_size,\n",
        "          validation_data=(X_test, Y_test),\n",
        "          epochs=epochs)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "Train on 7352 samples, validate on 2947 samples\n",
            "Epoch 1/30\n",
            "7352/7352 [==============================] - 30s 4ms/step - loss: 1.3207 - acc: 0.4329 - val_loss: 1.1474 - val_acc: 0.4706\n",
            "Epoch 2/30\n",
            "7352/7352 [==============================] - 29s 4ms/step - loss: 0.9877 - acc: 0.5702 - val_loss: 1.0286 - val_acc: 0.5046\n",
            "Epoch 3/30\n",
            "7352/7352 [==============================] - 31s 4ms/step - loss: 0.7947 - acc: 0.6477 - val_loss: 0.7681 - val_acc: 0.6074\n",
            "Epoch 4/30\n",
            "7352/7352 [==============================] - 30s 4ms/step - loss: 0.6952 - acc: 0.6578 - val_loss: 0.7221 - val_acc: 0.6060\n",
            "Epoch 5/30\n",
            "7352/7352 [==============================] - 30s 4ms/step - loss: 0.6491 - acc: 0.6802 - val_loss: 0.7290 - val_acc: 0.6169\n",
            "Epoch 6/30\n",
            "7352/7352 [==============================] - 31s 4ms/step - loss: 0.6374 - acc: 0.6857 - val_loss: 1.2811 - val_acc: 0.5877\n",
            "Epoch 7/30\n",
            "7352/7352 [==============================] - 30s 4ms/step - loss: 0.6218 - acc: 0.7231 - val_loss: 0.6598 - val_acc: 0.7194\n",
            "Epoch 8/30\n",
            "7352/7352 [==============================] - 27s 4ms/step - loss: 0.5557 - acc: 0.7578 - val_loss: 0.7062 - val_acc: 0.7333\n",
            "Epoch 9/30\n",
            "7352/7352 [==============================] - 29s 4ms/step - loss: 0.5000 - acc: 0.7933 - val_loss: 0.6462 - val_acc: 0.7618\n",
            "Epoch 10/30\n",
            "7352/7352 [==============================] - 29s 4ms/step - loss: 0.4565 - acc: 0.8069 - val_loss: 0.5785 - val_acc: 0.7737\n",
            "Epoch 11/30\n",
            "7352/7352 [==============================] - 29s 4ms/step - loss: 0.4371 - acc: 0.8171 - val_loss: 0.5561 - val_acc: 0.7788\n",
            "Epoch 12/30\n",
            "7352/7352 [==============================] - 28s 4ms/step - loss: 0.3866 - acc: 0.8437 - val_loss: 0.5607 - val_acc: 0.8273\n",
            "Epoch 13/30\n",
            "7352/7352 [==============================] - 30s 4ms/step - loss: 0.3693 - acc: 0.8819 - val_loss: 0.5133 - val_acc: 0.8687\n",
            "Epoch 14/30\n",
            "7352/7352 [==============================] - 27s 4ms/step - loss: 0.3033 - acc: 0.9106 - val_loss: 0.5015 - val_acc: 0.8799\n",
            "Epoch 15/30\n",
            "7352/7352 [==============================] - 31s 4ms/step - loss: 0.2572 - acc: 0.9226 - val_loss: 0.4646 - val_acc: 0.8823\n",
            "Epoch 16/30\n",
            "7352/7352 [==============================] - 28s 4ms/step - loss: 0.2539 - acc: 0.9232 - val_loss: 0.5301 - val_acc: 0.8826\n",
            "Epoch 17/30\n",
            "7352/7352 [==============================] - 28s 4ms/step - loss: 0.2158 - acc: 0.9331 - val_loss: 0.5799 - val_acc: 0.8612\n",
            "Epoch 18/30\n",
            "7352/7352 [==============================] - 31s 4ms/step - loss: 0.2564 - acc: 0.9244 - val_loss: 0.5184 - val_acc: 0.8680\n",
            "Epoch 19/30\n",
            "7352/7352 [==============================] - 28s 4ms/step - loss: 0.2175 - acc: 0.9319 - val_loss: 0.5122 - val_acc: 0.8870\n",
            "Epoch 20/30\n",
            "7352/7352 [==============================] - 28s 4ms/step - loss: 0.2374 - acc: 0.9321 - val_loss: 0.5969 - val_acc: 0.8711\n",
            "Epoch 21/30\n",
            "7352/7352 [==============================] - 29s 4ms/step - loss: 0.2009 - acc: 0.9392 - val_loss: 0.6558 - val_acc: 0.8714\n",
            "Epoch 22/30\n",
            "7352/7352 [==============================] - 30s 4ms/step - loss: 0.2106 - acc: 0.9387 - val_loss: 0.5078 - val_acc: 0.8782\n",
            "Epoch 23/30\n",
            "7352/7352 [==============================] - 28s 4ms/step - loss: 0.1870 - acc: 0.9411 - val_loss: 0.4839 - val_acc: 0.8812\n",
            "Epoch 24/30\n",
            "7352/7352 [==============================] - 30s 4ms/step - loss: 0.1881 - acc: 0.9399 - val_loss: 0.6952 - val_acc: 0.8721\n",
            "Epoch 25/30\n",
            "7352/7352 [==============================] - 28s 4ms/step - loss: 0.2000 - acc: 0.9391 - val_loss: 0.5929 - val_acc: 0.8856\n",
            "Epoch 26/30\n",
            "7352/7352 [==============================] - 28s 4ms/step - loss: 0.1904 - acc: 0.9412 - val_loss: 0.5378 - val_acc: 0.8823\n",
            "Epoch 27/30\n",
            "7352/7352 [==============================] - 28s 4ms/step - loss: 0.2367 - acc: 0.9358 - val_loss: 0.5179 - val_acc: 0.8697\n",
            "Epoch 28/30\n",
            "7352/7352 [==============================] - 27s 4ms/step - loss: 0.1854 - acc: 0.9468 - val_loss: 0.5344 - val_acc: 0.8931\n",
            "Epoch 29/30\n",
            "7352/7352 [==============================] - 28s 4ms/step - loss: 0.2251 - acc: 0.9402 - val_loss: 0.4379 - val_acc: 0.8918\n",
            "Epoch 30/30\n",
            "7352/7352 [==============================] - 28s 4ms/step - loss: 0.1702 - acc: 0.9457 - val_loss: 0.4320 - val_acc: 0.8938\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f2c870c70b8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "po4fXDsmq1hP",
        "colab_type": "code",
        "outputId": "d8fe40ba-acae-44fe-80d4-1c38fac97dd0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "# Confusion Matrix\n",
        "print(confusion_matrix(Y_test, model.predict(X_test)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Pred                LAYING  SITTING  ...  WALKING_DOWNSTAIRS  WALKING_UPSTAIRS\n",
            "True                                 ...                                      \n",
            "LAYING                 510        0  ...                   0                 2\n",
            "SITTING                  1      417  ...                   0                 4\n",
            "STANDING                 0      114  ...                   0                 2\n",
            "WALKING                  0        0  ...                  21                32\n",
            "WALKING_DOWNSTAIRS       1        2  ...                 400                15\n",
            "WALKING_UPSTAIRS         0        5  ...                   4               448\n",
            "\n",
            "[6 rows x 6 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "56XNePRJq1hd",
        "colab_type": "code",
        "outputId": "aecb11bb-911c-47b0-a002-85657d6dd0db",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "score = model.evaluate(X_test, Y_test)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2947/2947 [==============================] - 1s 317us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2INa0REEq1hv",
        "colab_type": "code",
        "outputId": "fccffc26-12cd-4e44-bc64-0c7f3ade97ca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "score"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.4319933943883621, 0.8937902952154734]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ST4fIhCBWuxx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7_epD0UAq1iE",
        "colab_type": "text"
      },
      "source": [
        "- With a simple 2 layer architecture we got 89.37% accuracy and a loss of 0.43\n",
        "- We can further imporve the performace with Hyperparameter tuning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r9sfbTe3WxCS",
        "colab_type": "text"
      },
      "source": [
        "**Tune the Dropout rate**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mYNZKb1QWv7L",
        "colab_type": "code",
        "outputId": "3990806c-b74e-43b8-9395-65b16c4cb2ec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 292
        }
      },
      "source": [
        "# Initiliazing the sequential model\n",
        "model = Sequential()\n",
        "# Configuring the parameters\n",
        "model.add(LSTM(n_hidden, input_shape=(timesteps, input_dim)))\n",
        "# Adding a dropout layer\n",
        "model.add(Dropout(0.75))\n",
        "# Adding a dense output layer with sigmoid activation\n",
        "model.add(Dense(n_classes, activation='sigmoid'))\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Large dropout rate: 0.75 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_1 (LSTM)                (None, 32)                5376      \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 6)                 198       \n",
            "=================================================================\n",
            "Total params: 5,574\n",
            "Trainable params: 5,574\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lTle2f9sYbmL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='rmsprop',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qcnlChD2YoGq",
        "colab_type": "code",
        "outputId": "9189c5ca-890a-47a3-ee1b-4e68a8074089",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model.fit(X_train,\n",
        "          Y_train,\n",
        "          batch_size=batch_size,\n",
        "          validation_data=(X_test, Y_test),\n",
        "          epochs=epochs)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "Train on 7352 samples, validate on 2947 samples\n",
            "Epoch 1/30\n",
            "7352/7352 [==============================] - 16s 2ms/step - loss: 1.4256 - accuracy: 0.4010 - val_loss: 1.2302 - val_accuracy: 0.4530\n",
            "Epoch 2/30\n",
            "7352/7352 [==============================] - 16s 2ms/step - loss: 1.1568 - accuracy: 0.4918 - val_loss: 1.0141 - val_accuracy: 0.5402\n",
            "Epoch 3/30\n",
            "7352/7352 [==============================] - 16s 2ms/step - loss: 0.9729 - accuracy: 0.5789 - val_loss: 0.8321 - val_accuracy: 0.6138\n",
            "Epoch 4/30\n",
            "7352/7352 [==============================] - 17s 2ms/step - loss: 0.8530 - accuracy: 0.6163 - val_loss: 0.7815 - val_accuracy: 0.6043\n",
            "Epoch 5/30\n",
            "7352/7352 [==============================] - 17s 2ms/step - loss: 0.8117 - accuracy: 0.6359 - val_loss: 0.7919 - val_accuracy: 0.6101\n",
            "Epoch 6/30\n",
            "7352/7352 [==============================] - 16s 2ms/step - loss: 0.9681 - accuracy: 0.5851 - val_loss: 1.2472 - val_accuracy: 0.4143\n",
            "Epoch 7/30\n",
            "7352/7352 [==============================] - 16s 2ms/step - loss: 0.8293 - accuracy: 0.6223 - val_loss: 0.7322 - val_accuracy: 0.6250\n",
            "Epoch 8/30\n",
            "7352/7352 [==============================] - 16s 2ms/step - loss: 0.7365 - accuracy: 0.6544 - val_loss: 0.7491 - val_accuracy: 0.6210\n",
            "Epoch 9/30\n",
            "7352/7352 [==============================] - 16s 2ms/step - loss: 0.7527 - accuracy: 0.6491 - val_loss: 0.7234 - val_accuracy: 0.6149\n",
            "Epoch 10/30\n",
            "7352/7352 [==============================] - 16s 2ms/step - loss: 0.7140 - accuracy: 0.6540 - val_loss: 0.7054 - val_accuracy: 0.6162\n",
            "Epoch 11/30\n",
            "7352/7352 [==============================] - 17s 2ms/step - loss: 0.6702 - accuracy: 0.6738 - val_loss: 0.9110 - val_accuracy: 0.5972\n",
            "Epoch 12/30\n",
            "7352/7352 [==============================] - 17s 2ms/step - loss: 0.6576 - accuracy: 0.6734 - val_loss: 0.6847 - val_accuracy: 0.6200\n",
            "Epoch 13/30\n",
            "7352/7352 [==============================] - 17s 2ms/step - loss: 0.6274 - accuracy: 0.6911 - val_loss: 0.6574 - val_accuracy: 0.6200\n",
            "Epoch 14/30\n",
            "7352/7352 [==============================] - 17s 2ms/step - loss: 0.6087 - accuracy: 0.6991 - val_loss: 0.8320 - val_accuracy: 0.6264\n",
            "Epoch 15/30\n",
            "7352/7352 [==============================] - 16s 2ms/step - loss: 0.6098 - accuracy: 0.6993 - val_loss: 0.6580 - val_accuracy: 0.7207\n",
            "Epoch 16/30\n",
            "7352/7352 [==============================] - 16s 2ms/step - loss: 0.5935 - accuracy: 0.7237 - val_loss: 0.7292 - val_accuracy: 0.6899\n",
            "Epoch 17/30\n",
            "7352/7352 [==============================] - 16s 2ms/step - loss: 0.6014 - accuracy: 0.7354 - val_loss: 0.6575 - val_accuracy: 0.7445\n",
            "Epoch 18/30\n",
            "7352/7352 [==============================] - 16s 2ms/step - loss: 0.5658 - accuracy: 0.7588 - val_loss: 0.5730 - val_accuracy: 0.7523\n",
            "Epoch 19/30\n",
            "7352/7352 [==============================] - 17s 2ms/step - loss: 0.5395 - accuracy: 0.7708 - val_loss: 0.5627 - val_accuracy: 0.7523\n",
            "Epoch 20/30\n",
            "7352/7352 [==============================] - 18s 2ms/step - loss: 0.5276 - accuracy: 0.7775 - val_loss: 0.6081 - val_accuracy: 0.7570\n",
            "Epoch 21/30\n",
            "7352/7352 [==============================] - 17s 2ms/step - loss: 0.5098 - accuracy: 0.7822 - val_loss: 0.5283 - val_accuracy: 0.7564\n",
            "Epoch 22/30\n",
            "7352/7352 [==============================] - 17s 2ms/step - loss: 0.5068 - accuracy: 0.7869 - val_loss: 0.5032 - val_accuracy: 0.7594\n",
            "Epoch 23/30\n",
            "7352/7352 [==============================] - 17s 2ms/step - loss: 0.4893 - accuracy: 0.7911 - val_loss: 0.5003 - val_accuracy: 0.7577\n",
            "Epoch 24/30\n",
            "7352/7352 [==============================] - 17s 2ms/step - loss: 0.4788 - accuracy: 0.8088 - val_loss: 0.5751 - val_accuracy: 0.7788\n",
            "Epoch 25/30\n",
            "7352/7352 [==============================] - 17s 2ms/step - loss: 0.4719 - accuracy: 0.8086 - val_loss: 0.4792 - val_accuracy: 0.7713\n",
            "Epoch 26/30\n",
            "7352/7352 [==============================] - 17s 2ms/step - loss: 0.4807 - accuracy: 0.8177 - val_loss: 0.5704 - val_accuracy: 0.8599\n",
            "Epoch 27/30\n",
            "7352/7352 [==============================] - 16s 2ms/step - loss: 0.4431 - accuracy: 0.8519 - val_loss: 0.4872 - val_accuracy: 0.8850\n",
            "Epoch 28/30\n",
            "7352/7352 [==============================] - 16s 2ms/step - loss: 0.4156 - accuracy: 0.8832 - val_loss: 0.4420 - val_accuracy: 0.8653\n",
            "Epoch 29/30\n",
            "7352/7352 [==============================] - 16s 2ms/step - loss: 0.3955 - accuracy: 0.8893 - val_loss: 0.4654 - val_accuracy: 0.8860\n",
            "Epoch 30/30\n",
            "7352/7352 [==============================] - 17s 2ms/step - loss: 0.3485 - accuracy: 0.9022 - val_loss: 0.5759 - val_accuracy: 0.8541\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.callbacks.History at 0x7f6abf320588>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p6X3kV6YayCO",
        "colab_type": "code",
        "outputId": "60f463d0-31aa-47f1-c6b4-dbf2d5874580",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "# Confusion Matrix\n",
        "print(confusion_matrix(Y_test, model.predict(X_test)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Pred                LAYING  SITTING  ...  WALKING_DOWNSTAIRS  WALKING_UPSTAIRS\n",
            "True                                 ...                                      \n",
            "LAYING                 510        0  ...                   0                27\n",
            "SITTING                  2      380  ...                   1                 1\n",
            "STANDING                 0       77  ...                   0                 0\n",
            "WALKING                  0        1  ...                  23                 9\n",
            "WALKING_DOWNSTAIRS       0        0  ...                 298               115\n",
            "WALKING_UPSTAIRS         0        0  ...                  24               417\n",
            "\n",
            "[6 rows x 6 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h4JfjvaLa6kl",
        "colab_type": "code",
        "outputId": "75ad7ca3-6589-430d-c9ad-dd0a93dabf00",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "score = model.evaluate(X_test, Y_test)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2947/2947 [==============================] - 1s 315us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3u7jxjyIbCkR",
        "colab_type": "code",
        "outputId": "2f58efdb-8843-4c43-dd87-eca9fc271ee8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "score"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.5759321995358251, 0.8540889024734497]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8UZ61pwlf8J9",
        "colab_type": "code",
        "outputId": "231bc3a2-84f0-4668-c48a-c6070031c51d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "source": [
        "model = Sequential()\n",
        "# Configuring the parameters\n",
        "model.add(LSTM(n_hidden, input_shape=(timesteps, input_dim)))\n",
        "# Adding a dropout layer\n",
        "model.add(Dropout(0.2))\n",
        "# Adding a dense output layer with sigmoid activation\n",
        "model.add(Dense(n_classes, activation='sigmoid'))\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_2 (LSTM)                (None, 32)                5376      \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 6)                 198       \n",
            "=================================================================\n",
            "Total params: 5,574\n",
            "Trainable params: 5,574\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GtqJqg5PgJcO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='rmsprop',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d-kQjQRfhAT9",
        "colab_type": "code",
        "outputId": "2efe1ee5-48b8-49f4-fef9-a85293ef1a6b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model.fit(X_train,\n",
        "          Y_train,\n",
        "          batch_size=batch_size,\n",
        "          validation_data=(X_test, Y_test),\n",
        "          epochs=epochs)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 7352 samples, validate on 2947 samples\n",
            "Epoch 1/30\n",
            "7352/7352 [==============================] - 17s 2ms/step - loss: 1.2395 - accuracy: 0.4954 - val_loss: 0.9725 - val_accuracy: 0.5697\n",
            "Epoch 2/30\n",
            "7352/7352 [==============================] - 16s 2ms/step - loss: 0.8660 - accuracy: 0.6270 - val_loss: 1.2941 - val_accuracy: 0.4869\n",
            "Epoch 3/30\n",
            "7352/7352 [==============================] - 17s 2ms/step - loss: 0.7043 - accuracy: 0.7018 - val_loss: 0.7861 - val_accuracy: 0.6797\n",
            "Epoch 4/30\n",
            "7352/7352 [==============================] - 16s 2ms/step - loss: 0.5475 - accuracy: 0.7783 - val_loss: 0.6620 - val_accuracy: 0.7285\n",
            "Epoch 5/30\n",
            "7352/7352 [==============================] - 16s 2ms/step - loss: 0.4577 - accuracy: 0.8200 - val_loss: 0.6436 - val_accuracy: 0.8103\n",
            "Epoch 6/30\n",
            "7352/7352 [==============================] - 16s 2ms/step - loss: 0.3739 - accuracy: 0.8887 - val_loss: 0.5980 - val_accuracy: 0.7862\n",
            "Epoch 7/30\n",
            "7352/7352 [==============================] - 16s 2ms/step - loss: 0.2728 - accuracy: 0.9129 - val_loss: 0.5211 - val_accuracy: 0.8537\n",
            "Epoch 8/30\n",
            "7352/7352 [==============================] - 16s 2ms/step - loss: 0.2511 - accuracy: 0.9200 - val_loss: 0.6755 - val_accuracy: 0.8124\n",
            "Epoch 9/30\n",
            "7352/7352 [==============================] - 16s 2ms/step - loss: 0.2285 - accuracy: 0.9275 - val_loss: 0.6115 - val_accuracy: 0.7686\n",
            "Epoch 10/30\n",
            "7352/7352 [==============================] - 16s 2ms/step - loss: 0.2336 - accuracy: 0.9257 - val_loss: 0.4884 - val_accuracy: 0.8704\n",
            "Epoch 11/30\n",
            "7352/7352 [==============================] - 16s 2ms/step - loss: 0.2461 - accuracy: 0.9260 - val_loss: 0.4348 - val_accuracy: 0.8765\n",
            "Epoch 12/30\n",
            "7352/7352 [==============================] - 17s 2ms/step - loss: 0.1885 - accuracy: 0.9354 - val_loss: 0.4202 - val_accuracy: 0.8863\n",
            "Epoch 13/30\n",
            "7352/7352 [==============================] - 16s 2ms/step - loss: 0.1732 - accuracy: 0.9414 - val_loss: 0.4591 - val_accuracy: 0.8829\n",
            "Epoch 14/30\n",
            "7352/7352 [==============================] - 16s 2ms/step - loss: 0.1817 - accuracy: 0.9348 - val_loss: 0.3578 - val_accuracy: 0.8938\n",
            "Epoch 15/30\n",
            "7352/7352 [==============================] - 16s 2ms/step - loss: 0.1754 - accuracy: 0.9416 - val_loss: 0.4221 - val_accuracy: 0.8972\n",
            "Epoch 16/30\n",
            "7352/7352 [==============================] - 16s 2ms/step - loss: 0.1628 - accuracy: 0.9450 - val_loss: 0.4362 - val_accuracy: 0.8972\n",
            "Epoch 17/30\n",
            "7352/7352 [==============================] - 17s 2ms/step - loss: 0.1530 - accuracy: 0.9465 - val_loss: 0.3101 - val_accuracy: 0.9080\n",
            "Epoch 18/30\n",
            "7352/7352 [==============================] - 16s 2ms/step - loss: 0.1611 - accuracy: 0.9461 - val_loss: 0.3391 - val_accuracy: 0.9023\n",
            "Epoch 19/30\n",
            "7352/7352 [==============================] - 17s 2ms/step - loss: 0.1628 - accuracy: 0.9436 - val_loss: 0.3221 - val_accuracy: 0.9162\n",
            "Epoch 20/30\n",
            "7352/7352 [==============================] - 17s 2ms/step - loss: 0.1363 - accuracy: 0.9517 - val_loss: 0.3790 - val_accuracy: 0.8972\n",
            "Epoch 21/30\n",
            "7352/7352 [==============================] - 17s 2ms/step - loss: 0.1391 - accuracy: 0.9475 - val_loss: 0.3588 - val_accuracy: 0.9104\n",
            "Epoch 22/30\n",
            "7352/7352 [==============================] - 16s 2ms/step - loss: 0.1598 - accuracy: 0.9444 - val_loss: 0.4131 - val_accuracy: 0.9080\n",
            "Epoch 23/30\n",
            "7352/7352 [==============================] - 17s 2ms/step - loss: 0.1528 - accuracy: 0.9430 - val_loss: 0.4566 - val_accuracy: 0.8962\n",
            "Epoch 24/30\n",
            "7352/7352 [==============================] - 17s 2ms/step - loss: 0.1458 - accuracy: 0.9452 - val_loss: 0.3988 - val_accuracy: 0.9013\n",
            "Epoch 25/30\n",
            "7352/7352 [==============================] - 17s 2ms/step - loss: 0.1321 - accuracy: 0.9518 - val_loss: 0.3481 - val_accuracy: 0.9033\n",
            "Epoch 26/30\n",
            "7352/7352 [==============================] - 17s 2ms/step - loss: 0.1399 - accuracy: 0.9520 - val_loss: 0.4650 - val_accuracy: 0.9077\n",
            "Epoch 27/30\n",
            "7352/7352 [==============================] - 17s 2ms/step - loss: 0.1445 - accuracy: 0.9493 - val_loss: 0.4535 - val_accuracy: 0.9036\n",
            "Epoch 28/30\n",
            "7352/7352 [==============================] - 17s 2ms/step - loss: 0.1385 - accuracy: 0.9499 - val_loss: 0.4646 - val_accuracy: 0.9006\n",
            "Epoch 29/30\n",
            "7352/7352 [==============================] - 17s 2ms/step - loss: 0.1246 - accuracy: 0.9523 - val_loss: 0.4865 - val_accuracy: 0.8911\n",
            "Epoch 30/30\n",
            "7352/7352 [==============================] - 17s 2ms/step - loss: 0.1366 - accuracy: 0.9521 - val_loss: 0.4328 - val_accuracy: 0.9053\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.callbacks.History at 0x7f6abe5c48d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QXsGgD8GjE_N",
        "colab_type": "code",
        "outputId": "85acf4c8-8953-4dbe-94d9-f7a681335268",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "# Confusion Matrix\n",
        "print(confusion_matrix(Y_test, model.predict(X_test)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Pred                LAYING  SITTING  ...  WALKING_DOWNSTAIRS  WALKING_UPSTAIRS\n",
            "True                                 ...                                      \n",
            "LAYING                 510        1  ...                   0                 0\n",
            "SITTING                  0      407  ...                   0                 3\n",
            "STANDING                 0      100  ...                   0                 0\n",
            "WALKING                  0        0  ...                  25                 6\n",
            "WALKING_DOWNSTAIRS       0        0  ...                 412                 6\n",
            "WALKING_UPSTAIRS         0        0  ...                   2               446\n",
            "\n",
            "[6 rows x 6 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NqTyE5AajMTC",
        "colab_type": "code",
        "outputId": "ba989ecc-3c48-4331-e36a-4c59b44a943c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "score = model.evaluate(X_test, Y_test)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2947/2947 [==============================] - 1s 315us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i0Y2PPw-jPw5",
        "colab_type": "code",
        "outputId": "d7dbbf66-6ced-44cb-cf49-702f908da082",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "score"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.43277596008456193, 0.9053274393081665]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CCcun1_oBe5i",
        "colab_type": "text"
      },
      "source": [
        "1.Performing tuning on drop-out rate we get a good accuracy arround 90.53 than previous model \n",
        "\n",
        "2.We can simillary perform hyper-parameter tuning on different parameter"
      ]
    }
  ]
}